{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Environment (conda_amld)",
      "language": "python",
      "name": "conda_amld"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "ae-vae-mnist.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpm7K44aJ8zo",
        "colab_type": "text"
      },
      "source": [
        "# Auto Encoders and Variational Auto Encoders on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s_UdVaxJ8zq",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we are going to demonstrate Auto Encoder and Variational Auto Encoder models on MNIST data.  \n",
        "\n",
        "We will go through many visualizations to develop good intuition on how these models work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT5affOiJ8zr",
        "colab_type": "text"
      },
      "source": [
        "### Set GPU for Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUC1H9JsJ8zs",
        "colab_type": "text"
      },
      "source": [
        "<p id=\"7ecb\" class=\"gy gz ef at ha b hb ja hd jb hf jc hh jd hj je hl\" data-selectable-paragraph=\"\">It is so simple to alter default hardware <strong class=\"ha hm\">(CPU to GPU or vice versa)</strong>; just follow <strong class=\"ha hm\">Edit &gt; Notebook settings</strong> or <strong class=\"ha hm\">Runtime&gt;Change runtime type </strong>and <strong class=\"ha hm\">select GPU </strong>as <strong class=\"ha hm\">Hardware accelerator</strong>.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYcDNx-gJ8zs",
        "colab_type": "text"
      },
      "source": [
        "![tittle](https://miro.medium.com/max/740/1*WNovJnpGMOys8Rv7YIsZzA.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ92_QjBJ8zt",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tco8MFm5J8zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python lib\n",
        "import os\n",
        "from typing import List, Tuple\n",
        "\n",
        "# Scientific utilities\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm as ndist\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "# Vizualisations\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzJpGRZTJ8zx",
        "colab_type": "text"
      },
      "source": [
        "### Globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpmJdP34J8zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = 'data'\n",
        "\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4JdDyG-J8z0",
        "colab_type": "text"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Ca6O5gJ8z0",
        "colab_type": "text"
      },
      "source": [
        "Conveniently, PyTorch comes with pre-defined MNIST dataset so we are going to use it directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJrUEG22J8z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mnist_ds(train: bool):\n",
        "\n",
        "    return torchvision.datasets.MNIST(DATA_DIR, \n",
        "                                      train=train, \n",
        "                                      transform=transforms.Compose([\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                ]), \n",
        "                                      target_transform=None, \n",
        "                                      download=True)\n",
        "\n",
        "def get_mnist_dls():\n",
        "    \n",
        "    train_ds = get_mnist_ds(train=True)\n",
        "    valid_ds = get_mnist_ds(train=False)\n",
        "    \n",
        "    return (torch.utils.data.DataLoader(train_ds, \n",
        "                                        batch_size=BATCH_SIZE, \n",
        "                                        shuffle=True, \n",
        "                                        pin_memory=False),\n",
        "            \n",
        "            torch.utils.data.DataLoader(valid_ds, \n",
        "                                        batch_size=2 * BATCH_SIZE, \n",
        "                                        shuffle=False, \n",
        "                                        pin_memory=False))\n",
        "\n",
        "train_dl, valid_dl = get_mnist_dls()\n",
        "\n",
        "len(train_dl.dataset), len(valid_dl.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QlJQjdoMJ8z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# displaying some of the images with some stats. \n",
        "\n",
        "for i, (x, y) in enumerate(train_dl):\n",
        "    print(x.shape, x.mean(), x.std(), x.min(), x.max())\n",
        "    plt.imshow(x[0][0], cmap='gray')\n",
        "    plt.show()\n",
        "    if i > 2: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm_M9_4MJ8z6",
        "colab_type": "text"
      },
      "source": [
        "## Training Vanilla Auto Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR8bpANPJ8z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is helper function for initializing weights of the model.\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "\n",
        "    for m in m.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj6kjAllJ8z9",
        "colab_type": "text"
      },
      "source": [
        "We fill be using simle encoder with one hidden layer and Relu activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUB4keVJ8z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, inp_shape: Tuple[int, int], hidden_dim: int, out_dim: int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.enc = nn.Sequential(nn.Flatten(),\n",
        "                                 nn.Linear(np.prod(inp_shape), hidden_dim),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(hidden_dim, out_dim))\n",
        "        \n",
        "        init_weights(self)\n",
        "        \n",
        "    def forward(self, x): return self.enc(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaDZEcfDJ8z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Encoder(inp_shape=(28, 28), hidden_dim=512, out_dim=256)\n",
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_ykVtrvJ80B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, inp_shape: Tuple[int, int], hidden_dim: int, out_dim: int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.inp_shape = inp_shape\n",
        "        \n",
        "        self.dec = nn.Sequential(nn.Linear(out_dim, hidden_dim),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(hidden_dim, np.prod(inp_shape)))\n",
        "        \n",
        "        init_weights(self)\n",
        "        \n",
        "    def forward(self, x): return torch.sigmoid(self.dec(x)).view(x.shape[0], *self.inp_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6iTaQvFJ80D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Decoder(inp_shape=(28, 28), hidden_dim=512, out_dim=256)\n",
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3JZPCmbJ80F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here we just combine encoder and decoder modules from above\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, inp_shape: Tuple[int, int], hidden_dim: int, out_dim: int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.ae = nn.Sequential(Encoder(inp_shape, hidden_dim, out_dim),\n",
        "                                Decoder(inp_shape, hidden_dim, out_dim))\n",
        "        \n",
        "    def forward(self, x): return self.ae(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPv_vPyCJ80H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = AutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=256)\n",
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTCn6Iz6J80J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we make sure that auto encoder output has same shape as the input\n",
        "\n",
        "o = torch.randn(BATCH_SIZE, 1, 28, 28)\n",
        "assert m(o).shape == o.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mITVqsspJ80K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_summary(valid_dl: DataLoader, model: nn.Module):\n",
        "    \"\"\"This is a helper function for visualizing model output quality during the training process.\"\"\"\n",
        "    \n",
        "    N_SAMPLES = 15\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    actuals, preds = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(valid_dl.dataset):\n",
        "            \n",
        "            actuals.append(x)\n",
        "            \n",
        "            recon_x = model(x.unsqueeze(0).cuda()).cpu()\n",
        "            \n",
        "            preds.append(recon_x.squeeze(0))\n",
        "            \n",
        "            if i + 1 == N_SAMPLES:\n",
        "                break\n",
        "                \n",
        "    model.train()\n",
        "            \n",
        "    grid = make_grid([*actuals, *preds], pad_value=1, padding=1, nrow=N_SAMPLES)\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    plt.imshow(grid.permute(1, 2, 0))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "        \n",
        "def train_ae(train_dl: DataLoader, \n",
        "             valid_dl: DataLoader,\n",
        "             model: nn.Module,\n",
        "             n_epochs: int,\n",
        "             max_iters: int = -1):\n",
        "    \"\"\"Training Loop\"\"\"\n",
        "    \n",
        "    LOG_INTERVAL = 5\n",
        "    SUMMARY_INTERVAL = 10\n",
        "    \n",
        "    model = model.cuda() # moving our model on GPU.\n",
        "    \n",
        "    # defining loss function and optimizer (we will use Adam here)\n",
        "    crit = nn.MSELoss(reduction='mean')\n",
        "    optim = torch.optim.Adam(model.parameters())\n",
        "    \n",
        "    acc_loss = 0\n",
        "    \n",
        "    i = 1\n",
        "    for epoch in range(n_epochs):\n",
        "        for x, _ in train_dl:\n",
        "            \n",
        "            optim.zero_grad()\n",
        "            \n",
        "            x = x.cuda()\n",
        "            \n",
        "            x_recon = model(x)\n",
        "            \n",
        "            loss = crit(x, x_recon)\n",
        "            \n",
        "            acc_loss += loss.item()\n",
        "            \n",
        "            loss.backward() # computing the gradients\n",
        "            \n",
        "            optim.step() # updating model weights\n",
        "            \n",
        "            if (i + 1) % LOG_INTERVAL == 0:\n",
        "                print('epoch %d | iter %d | loss %.5f' % (epoch + 1, i + 1, acc_loss / LOG_INTERVAL))\n",
        "                acc_loss = 0\n",
        "                \n",
        "            if (i + 1) % SUMMARY_INTERVAL == 0:\n",
        "                show_summary(valid_dl, model)\n",
        "                \n",
        "            i += 1\n",
        "            \n",
        "            if i == max_iters:\n",
        "                return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmJ2Wa9cJ80M",
        "colab_type": "text"
      },
      "source": [
        "Now we will train the mode. You can play with out_dim parameter (latent vector size) and see how it affects training speed and image restoration quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryk_VP3wJ80N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will be training the model for 500 iterations\n",
        "\n",
        "ae = AutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=20)\n",
        "\n",
        "train_ae(train_dl, valid_dl, ae, 50, 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YtFRBNdJ80O",
        "colab_type": "text"
      },
      "source": [
        "## Training Vanilla Variational Auto Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGEzZBvrJ80P",
        "colab_type": "text"
      },
      "source": [
        "Now we will reuse Encoder and Decoder modules from above to build a simple variational auto encoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3GWapyMJ80P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoEncoder(nn.Module):\n",
        "    def __init__(self, inp_shape: Tuple[int, int], hidden_dim: int, out_dim: int, z_dim: int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.enc = Encoder(inp_shape, hidden_dim, out_dim)\n",
        "        self.dec = Decoder(inp_shape, hidden_dim, out_dim)\n",
        "        \n",
        "        self.mu     = nn.Linear(out_dim, z_dim)\n",
        "        self.logvar = nn.Linear(out_dim, z_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(z_dim, out_dim)\n",
        "        \n",
        "        init_weights(self)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        \"\"\"This function takes x and produces mean and log(variance) for approximate posterior Q(z|x)\"\"\"\n",
        "        \n",
        "        enc = self.enc(x)\n",
        "        \n",
        "        mu, logvar = self.mu(enc), self.logvar(enc)\n",
        "        \n",
        "        return mu, logvar\n",
        "        \n",
        "    def sample_z(self, mu, logvar):\n",
        "        \"\"\"This function takes mean and log(variance) and applies reparametrization trick.\"\"\"\n",
        "        \n",
        "        eps = torch.rand_like(mu)\n",
        "        \n",
        "        return mu + eps * torch.exp(0.5 * logvar)\n",
        "    \n",
        "    def decode(self, z):\n",
        "        \"\"\"This function accepts z - latent vector and produces reconstruction of original input.\"\"\"\n",
        "        \n",
        "        return self.dec(self.fc(z))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        mu, logvar = self.encode(x)\n",
        "        \n",
        "        z = self.sample_z(mu, logvar)\n",
        "        \n",
        "        return self.decode(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRB4IAn0J80R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = VariationalAutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=256, z_dim=2)\n",
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h7jZmhJ80T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def elbo_loss(inp, tar, mu, logvar, alpha: float = 1, beta: float = 1):\n",
        "    \"\"\"This function defines ELBO loss, KL DIV + RECONSTRUCTION.\"\"\"\n",
        "    \n",
        "    recon_loss = nn.functional.mse_loss(inp, tar, reduction='none').sum(dim=(1, 2, 3))\n",
        "            \n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=-1)\n",
        "\n",
        "    loss = torch.mean(alpha * kld_loss + beta * recon_loss)\n",
        "    \n",
        "    return loss, torch.mean(recon_loss), torch.mean(kld_loss)\n",
        "\n",
        "def train_vae(train_dl: DataLoader, \n",
        "              valid_dl: DataLoader,\n",
        "              model: nn.Module,\n",
        "              n_epochs: int,\n",
        "              max_iters: int = -1):\n",
        "    \n",
        "    LOG_INTERVAL = 20\n",
        "    SUMMARY_INTERVAL = 100\n",
        "    \n",
        "    model = model.cuda()\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    \n",
        "    acc_recon_loss, acc_kld_loss, acc_loss = 0, 0, 0\n",
        "    \n",
        "    i = 1\n",
        "    for epoch in range(n_epochs):\n",
        "        for x, y in train_dl:\n",
        "            \n",
        "            optim.zero_grad()\n",
        "            \n",
        "            x = x.cuda()\n",
        "\n",
        "            mu, logvar = model.encode(x)\n",
        "            \n",
        "            z = model.sample_z(mu, logvar)\n",
        "        \n",
        "            x_recon = model.decode(z)\n",
        "        \n",
        "            loss, recon_loss, kld_loss = elbo_loss(x_recon, x, mu, logvar, alpha=1, beta=1)\n",
        "\n",
        "            acc_recon_loss += recon_loss.item()\n",
        "            acc_kld_loss += kld_loss.item()\n",
        "            acc_loss += loss.item()\n",
        "            \n",
        "            loss.backward()\n",
        "            \n",
        "            optim.step()\n",
        "            \n",
        "            if (i + 1) % LOG_INTERVAL == 0:\n",
        "                \n",
        "                print('epoch %d | iter %d | loss %.5f | KL loss %.5f | recon loss %.5f ' % \n",
        "                      (epoch + 1, i + 1, acc_loss / LOG_INTERVAL, acc_kld_loss / LOG_INTERVAL, acc_recon_loss / LOG_INTERVAL))\n",
        "                \n",
        "                acc_recon_loss, acc_kld_loss, acc_loss = 0, 0, 0\n",
        "                \n",
        "            if (i + 1) % SUMMARY_INTERVAL == 0:\n",
        "                show_summary(valid_dl, model)\n",
        "                \n",
        "            i += 1\n",
        "            \n",
        "            if i == max_iters:\n",
        "                return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Ik42URyEJ80W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will be training the model for 500 iterations\n",
        "\n",
        "vae = VariationalAutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=256, z_dim=20)\n",
        "\n",
        "train_vae(train_dl, valid_dl, vae, 50, 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzkChhZvJ80X",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing Latent Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4QQmPGwJ80Y",
        "colab_type": "text"
      },
      "source": [
        "In this section we will work through several visualizations of above models to develop good intuition how these models work.  \n",
        "\n",
        "In all below cases we will be using models with 2D latent space since its directly plottable without need of dimensionality reduction techniques, such as PCA. \n",
        "\n",
        "Besides, we will use pre-trained model weights because 2D latent space model training requires approx. 50 epochs on the data that would take long time to do it here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lblPC4SJ80Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('ae-20.model'):\n",
        "    !wget https://maxinai-public-datasets.s3.eu-central-1.amazonaws.com/workshop-amld2020/ae-20.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRiry6o2J80a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading pre-trained Auto Encoder with 2D latent space\n",
        "\n",
        "ae = AutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=2)\n",
        "ae.load_state_dict(torch.load('ae-20.model'))\n",
        "ae.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJO0UckrJ80c",
        "colab_type": "text"
      },
      "source": [
        "We will start by visualizing the clusters of digits by plotting latent vectors of datapoints from validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBytFZv_J80d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here we will go over validation set and generate latent representation of every data point by using encoder part \n",
        "# of the model. X and Y coordinates of this latent vectors, along with the label are stored in Dataframe.\n",
        "\n",
        "z, labels = [], []\n",
        "for i, (x, y) in enumerate(valid_dl):\n",
        "    enc = ae.ae[0](x).detach() # doing forward-pass only on encoder part.\n",
        "    z.append(enc)\n",
        "    labels.append(y)\n",
        "z = torch.cat(z, dim=0)\n",
        "labels = torch.cat(labels, dim=0)\n",
        "\n",
        "df = pd.DataFrame({'x': z[:,0].numpy(), \n",
        "                   'y': z[:,1].numpy(),\n",
        "                   'label': labels.numpy()})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZVzyUgqJ80e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the dataframe by assigning different color to different digit (label)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "sns.scatterplot(x=\"x\", y=\"y\", hue=\"label\", palette=sns.color_palette(\"Paired\", 10), data=df, legend=\"full\")\n",
        "plt.title('Vizualising Latent Vectors for Valid Set');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUpmiobPJ80f",
        "colab_type": "text"
      },
      "source": [
        "Now we will do the same visualization for variational auto-encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eK0owzAJ80g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('vae-60.model'):\n",
        "    !wget https://maxinai-public-datasets.s3.eu-central-1.amazonaws.com/workshop-amld2020/vae-60.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTsODaFHJ80h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading pre-trained Variational Auto Encoder with 2D latent space\n",
        "\n",
        "vae = VariationalAutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=256, z_dim=2)\n",
        "vae.load_state_dict(torch.load('vae-60.model'))\n",
        "vae.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf2xNB_QJ80j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viz_vae_clusters(vae: nn.Module):\n",
        "\n",
        "    vae.cuda()\n",
        "    z, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(valid_dl):\n",
        "            x = x.cuda()\n",
        "            mu, _ = vae.encode(x)\n",
        "            z.append(mu.cpu())\n",
        "            labels.append(y)\n",
        "    z = torch.cat(z, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "\n",
        "    df = pd.DataFrame({'x': z[:,0].numpy(), \n",
        "                  'y': z[:,1].numpy(),\n",
        "                  'label': labels.numpy()})\n",
        "\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    sns.scatterplot(x=\"x\", y=\"y\", hue=\"label\", palette=sns.color_palette(\"Paired\", 10), data=df, legend=\"full\")\n",
        "    plt.title('Vizualising Latent Vectors for Valid Set');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFsVIFXcJ80k",
        "colab_type": "text"
      },
      "source": [
        "As you will see from below plot, point cloud of latent vectors has circular shape centered at origin as opposed to \n",
        "Auto Encoder case. This behaviour is imposed by KL Divergence component of the loss, that forces latent distribution to be close to the isotropic Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAJHfXCSJ80l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "viz_vae_clusters(vae)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxgHf_5VJ80n",
        "colab_type": "text"
      },
      "source": [
        "Now we will see what happens if we remove KL Divergence term and only use reconstruction loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM3wPXikJ80n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('vae-60-kl0.model'):\n",
        "    !wget https://maxinai-public-datasets.s3.eu-central-1.amazonaws.com/workshop-amld2020/vae-60-kl0.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTsvLnV7J80p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading trained Variational AutoEncoder with 2D latent space and without KL component\n",
        "\n",
        "vae_kl = VariationalAutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=256, z_dim=2)\n",
        "vae_kl.load_state_dict(torch.load('vae-60-kl0.model'))\n",
        "vae_kl.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEXEzHuPJ80q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "viz_vae_clusters(vae_kl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTQ_KHS3J80r",
        "colab_type": "text"
      },
      "source": [
        "Now we will show that latent space of Variational Auto-Encoder is continuous, i.e. close latent vectors produce similar looking images at the output.\n",
        "\n",
        "We will do it by visualizing whole 2D space at once (run the below cell to see what it means).\n",
        "\n",
        "We will exploit the fact that our latent vectors are distributed somewhat similar to 2D isotropic gaussian centered at origin (refer above plots). Having said this, we need to generate 2D meshgrid where distribution of points correspond to 2D Gaussian.\n",
        "\n",
        "\n",
        "To do this, we gonna first generate 2D meshgrid in $[0, 1]^2$ unit square and use inverse CDF (Comulative Distribution Function) of Gaussian to translate our meshgrid to the latent space.\n",
        "\n",
        "Finally, we decode every point in latent space and visualize output images as 2D plot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcI11r-8J80s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_mnist_manifold_vae(model: nn.Module, size: int = 20):\n",
        "    \"\"\"This function takes a trained VAE with z_dim=2 and visualizes its latent space.\"\"\"\n",
        "\n",
        "    # generate a 2D point cloud of latent space using inverse CDF of Standard Gaussian.\n",
        "    x_axes = ndist.ppf(np.linspace(0.05, 0.95, size))\n",
        "    y_axes = ndist.ppf(np.linspace(0.05, 0.95, size))\n",
        "\n",
        "    # preparing input to decoder.\n",
        "    z = []\n",
        "    for i, y in enumerate(x_axes):\n",
        "        for j, x in enumerate(y_axes):\n",
        "            z.append(torch.Tensor([x, y]))\n",
        "    z = torch.stack(z)\n",
        "    \n",
        "    # decoding latent vectors\n",
        "    preds = model.decode(z).detach()\n",
        "    \n",
        "    # rendering a single image from predictions.\n",
        "    grid = make_grid(preds, pad_value=1, padding=1, nrow=size)[0].numpy()\n",
        "    \n",
        "    # showing the image.\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('2D Latent Space')\n",
        "    plt.show()\n",
        "\n",
        "draw_mnist_manifold_vae(vae.cpu(), size=25);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5SN_kUUJ80u",
        "colab_type": "text"
      },
      "source": [
        "Doing similar visualization on Auto Encoder produces bad result, because the latent space usually isn't continuous.\n",
        "\n",
        "More specifically, in some regions of space we get outputs that <b>don't represent valid digits</b>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smpmxT8SJ80u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_mnist_manifold_ae(model: nn.Module, size: int = 20):\n",
        "    \"\"\"This function takes a trained VAE with z_dim=2 and visualizes its latent space.\"\"\"\n",
        "\n",
        "    # generate a 2D point cloud of latent space using inverse CDF of Standard Gaussian.\n",
        "    x_axes = np.linspace(-8, 6, size)\n",
        "    y_axes = np.linspace(-1.5, 10, size)\n",
        "\n",
        "    # assembling the latent vector of shape (size^2, 2) to be fed into the decoder.\n",
        "    z = []\n",
        "    for i, y in enumerate(x_axes):\n",
        "        for j, x in enumerate(y_axes):\n",
        "            z.append(torch.Tensor([x, y]))\n",
        "    z = torch.stack(z)\n",
        "    \n",
        "    # generating predictions\n",
        "    preds = model.ae[1](z).detach()\n",
        "    \n",
        "    # rendering a single image from predictions.\n",
        "    grid = make_grid(preds, pad_value=1, padding=1, nrow=size)[0].numpy()\n",
        "    \n",
        "    # showing the image.\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('2D Latent Space')\n",
        "    plt.show()\n",
        "    \n",
        "draw_mnist_manifold_ae(ae.cpu(), 25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOGnSAiTJ80w",
        "colab_type": "text"
      },
      "source": [
        "## Sampling from VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8foaCXMHJ80w",
        "colab_type": "text"
      },
      "source": [
        "One of the goals of generative models is being able to effectively sample from learned data distribution.  \n",
        "\n",
        "In case of VAE, we take trained model, remove its encoder, and use decoder to transform gaussian noise into data point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBTuAsKkJ80x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate 100 gaussian noise vectors\n",
        "\n",
        "z = torch.empty(100, 2).normal_(0, 1)\n",
        "z.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHekjwaOJ80y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decode the noise vectors\n",
        "\n",
        "images = vae.decode(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "updk8PTdJ80z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the result\n",
        "\n",
        "grid = make_grid(images, pad_value=1, padding=1, nrow=10)[0].detach().numpy()\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(grid, cmap='gray');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaIB8sr2J800",
        "colab_type": "text"
      },
      "source": [
        "Continuity of latent space implies certain <b>robustness</b> agains noise.  \n",
        "\n",
        "We can take latent vector corresponding to some digit, add small noise to it and still get output very similar to that digit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr2qyqIHJ801",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here we calculate average latent vector for every digit 0-9.\n",
        "# average is taken to make sure we have representative vector, i.e we are somewhere close to the centroid of that digit's cluster.\n",
        "\n",
        "locs = [torch.zeros(1, 1, 2) for _ in range(10)] # list for keeping latent vectors corresponding to digits 0-9\n",
        "locs_cnt = [0] * 10 # list for keeping counts of latent vectors per digits. \n",
        "\n",
        "for i, (x, y) in enumerate(valid_dl.dataset):\n",
        "    mu, _ = vae.encode(x.unsqueeze(0))\n",
        "    locs[y] += mu\n",
        "    locs_cnt[y] += 1\n",
        "    if i > 500:\n",
        "        break\n",
        "        \n",
        "for i in range(len(locs)): locs[i] /= locs_cnt[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv9BfOerJ802",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we show how to generate same digit in different \"handwriting\" by taking average vector of that \n",
        "# digit and adding small noise. \n",
        "\n",
        "for i in range(10):\n",
        "    x_recon = []\n",
        "    for j in range(10):\n",
        "        loc = locs[i].clone()\n",
        "        loc += torch.empty_like(loc).normal_()/8\n",
        "        x_recon.append(vae.decode(loc))\n",
        "        \n",
        "    x_recon = torch.cat(x_recon)\n",
        "    \n",
        "    grid = make_grid(x_recon, pad_value=1, padding=1, nrow=20)[0].detach().numpy()\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}